### Job Description
Job Title: Senior/Staff Level Data Engineer Project Overview: HEB is seeking to enhance its data infrastructure by migrating billing data from AWS and Azure to Google Cloud Platform (GCP). The goal is to create a centralized repository for all public cloud data, which will support the development of a machine learning (ML) forecasting model. This model will enable HEB leaders to make informed decisions based on accurate and comprehensive data. Key Responsibilities:Data Migration and Integration:Migrate AWS and Azure billing data to GCP: Transfer existing data from AWS and Azure to GCP, ensuring data integrity and consistency.Create a separate repository: Establish a dedicated storage solution within GCP to house this data.Data Processing and ETL Pipelines:Expert in GCP and BigQuery: Utilize BigQuery for efficient data querying and analysis.Understand cloud data flow and ETL pipelining: Design and implement ETL (Extract, Transform, Load) processes to streamline data ingestion and processing.Machine Learning and Decision Support:Develop an ML forecasting model: Use the centralized data to create models that can predict trends and outcomes, aiding decision-making.Help leaders make data-driven decisions: Provide insights and recommendations based on the ML modelâ€™s outputs. Project Timeline and Requirements:MVP by End of March: The minimum viable product (MVP) should be ready by the end of March, focusing initially on public cloud data.4-Month Contract: The project is expected to be completed within four months, with some flexibility in the timeline.Senior/Staff Level Data Engineer: A highly skilled data engineer with extensive experience in GCP and BigQuery is needed to lead this project.Additional Support: A Business Systems Analyst (BSA) will assist with documentation, while the data engineer will handle architecture, data ingestion, process pipelining, testing, and validation.
--------------------------------------------------
### Cosine Distance
0.7021
