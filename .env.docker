# API Authentication
SECRET_KEY="your-secret-key-here"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=60
INTERNAL_API_KEY="your-api-key-here"

# Service Configuration
SERVICE_NAME="matching_service"
ENVIRONMENT="development"
DEBUG=True

# Logging Configuration
LOG_LEVEL="INFO"
JSON_LOGS=True
LOG_RETENTION="7 days"
ENABLE_LOGSTASH=False

# Database Connections
# Using localhost since we're using host network mode in docker-compose
DATABASE_URL="postgresql://testuser:testpassword@localhost:5432/matching"
MONGODB="mongodb://localhost:27017"
MONGODB_DATABASE="resumes"

# Database Connection Pooling
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10
DB_POOL_TIMEOUT=30.0
DB_POOL_MAX_IDLE=300
DB_STATEMENT_TIMEOUT=60000

# Vector Optimization Settings
VECTOR_INDEX_TYPE="ivfflat"
VECTOR_IVF_LISTS=100
VECTOR_IVF_PROBES=10
VECTOR_HNSW_M=16
VECTOR_HNSW_EF_CONSTRUCTION=64
VECTOR_HNSW_EF_SEARCH=40

# Message Queue
RABBITMQ_URL="amqp://guest:guest@localhost:5672/"
MATCHING_QUEUE="job_to_apply_queue"

# Redis Configuration
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=""
REDIS_CACHE_TTL=300
REDIS_ENABLED=True

# AI/LLM Integration
OPENAI_API_KEY="your-openai-api-key"
LLM_BASE_URL="https://openrouter.ai/api/v1"
LLM_MODEL_NAME="openai/gpt-4o-mini"

# Metrics Configuration
METRICS_ENABLED=True
METRICS_DEBUG=False
METRICS_BACKEND="statsd"
METRICS_PREFIX="matching_service"
METRICS_SAMPLE_RATE=1.0
METRICS_STATSD_HOST="localhost"
METRICS_STATSD_PORT=8125

# Metrics Collection
METRICS_COLLECTION_ENABLED=True
SYSTEM_METRICS_ENABLED=True
SYSTEM_METRICS_INTERVAL=60

# Performance Thresholds
SLOW_REQUEST_THRESHOLD_MS=1000.0
SLOW_QUERY_THRESHOLD_MS=500.0
SLOW_OPERATION_THRESHOLD_MS=2000.0